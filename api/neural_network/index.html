
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../PINN/">
      
      
        <link rel="next" href="../callbacks/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.7">
    
    
      
        <title>Neural Network - PINN-ADT</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4b4a2bd9.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="PINN-ADT" class="md-header__button md-logo" aria-label="PINN-ADT" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            PINN-ADT
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Neural Network
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="PINN-ADT" class="md-nav__button md-logo" aria-label="PINN-ADT" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    PINN-ADT
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Главная
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Руководство
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Руководство
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/getting_started/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Начало работы
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../guide/ensemble/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ансамблирование моделей
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../PINN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PINN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Neural Network
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Neural Network
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#feed-forward-neural-network" class="md-nav__link">
    Feed forward neural network
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xavier-feed-forward-neural-network" class="md-nav__link">
    Xavier feed forward neural network
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#residual-neural-network" class="md-nav__link">
    Residual neural network
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#residual-block" class="md-nav__link">
    Residual block
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#densely-connected-linear-networks" class="md-nav__link">
    Densely connected linear networks
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#densely-block" class="md-nav__link">
    Densely block
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gelu" class="md-nav__link">
    GELU
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sine" class="md-nav__link">
    Sine
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../callbacks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Callbacks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../problems/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Problems
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../ensemble/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ensemble
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../geometry/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Geometry
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../trainer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trainer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../regularization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Regularization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../mesh/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Mesh
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../how_to_use/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Как писать документацию
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#feed-forward-neural-network" class="md-nav__link">
    Feed forward neural network
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xavier-feed-forward-neural-network" class="md-nav__link">
    Xavier feed forward neural network
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#residual-neural-network" class="md-nav__link">
    Residual neural network
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#residual-block" class="md-nav__link">
    Residual block
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#densely-connected-linear-networks" class="md-nav__link">
    Densely connected linear networks
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#densely-block" class="md-nav__link">
    Densely block
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gelu" class="md-nav__link">
    GELU
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sine" class="md-nav__link">
    Sine
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="_1">Нейронные сети</h1>
<p>В бибилотеке реализованы различные архитектуры нейронных сетей:
- Feed forward neural network
- Xavier feed forward neural network
- Residual neural network
- Densely connected linear networks </p>
<p>Помимо архитектур было реализовано <a href="https://github.com/liskiran/pinn_docs/blob/main/docs/api/ensemble.md">ансамблирование</a> моделей, при котором существует возможность использование всех моделей разом для улучшения предсказаний. Более того в архитектурах моделей используются адаптивная функция активации <a href="#siren">Siren</a> и оптимизированная функция <a href="#gelu">GeLU</a> для оптимизации процесса обучения.</p>
<h2 id="feed-forward-neural-network">Feed forward neural network</h2>
<pre><code>CLASS: src.neural_network.FNN(layers_all: List[int])
</code></pre>
<p>Модель включает в себя целостный класс FNN, где задается количество нейронов. Архитектура FNN включает линейные слои, которые связаны между собой адаптивной функцией активации <a href="#siren">Siren</a> и функциями <a href="#gelu">GeLU</a>.</p>
<p><strong>Параметры</strong></p>
<ul>
<li><strong>layers_all</strong> (List) - список нейронов по слоям для обучения.</li>
</ul>
<blockquote>
<p><strong><em>Важно:</em></strong>  Первое и последнее значение массива нейронов должно соответствовать геометрии задачи и количеству выводов.</p>
</blockquote>
<p><strong>Метод</strong></p>
<pre><code>forward(x: torch.Tensor)
</code></pre>
<p><strong>Параметр</strong></p>
<pre><code>x (torch.Tensor) - входной тензор данных для прямого прохода модели.
</code></pre>
<p>Выполняет прямой проход обучения модели. </p>
<p><strong>Пример использования:</strong></p>
<pre><code class="language-python">from src.neural_network import FNN

# Определение входных и выходных нейронов 
input_size = 2

output_size = 1

# Определение слоев нейронов в модели
layers = [input_size, 128, 128, 128, output_size]


# Определение модели
model = FNN(layers_all=layers)


output = model(input_tensor)

</code></pre>
<h2 id="xavier-feed-forward-neural-network">Xavier feed forward neural network</h2>
<pre><code>CLASS: src.neural_network.XavierFNN (layers_all: List[int], init_mode: str)
</code></pre>
<p>Модель включает в себя полноценный класс XavierFNN, в котором задается количество нейронов и метод инициализации весов Ксавьера. Архитектура сети включает линейные слои, которые связаны между собой функциями активации <a href="#sine">Siren</a> и <a href="#gelu">GeLU</a>. Освноная особенность данной архитектуры заключается в возможности инициализации весов для обучения модели.</p>
<p><strong>Параметры</strong></p>
<ul>
<li><strong>layers_all</strong> (List) - список нейронов по слоям для обучения.</li>
<li><strong>init_mode</strong> (str) - метод инициализации весов ‘norm’/’uniform’.</li>
</ul>
<p><strong>Метод</strong></p>
<pre><code>forward(input: torch.Tensor)
</code></pre>
<p><strong>Параметр</strong></p>
<pre><code>input (torch.Tensor) - входной тензор данных для прямого прохода модели.
</code></pre>
<p>Выполняет прямой проход обучения модели. </p>
<p><strong>Примеры использования:</strong></p>
<pre><code class="language-python">from src.neural_network import XavierFNN

# Определение входных и выходных нейронов 
input_size = 2

output_size = 1

# Определение слоев нейронов в модели и  метода инициализации весов
layers = [input_size, 128, 128, 128, output_size]
mode= 'norm'

# Определение модели
model = XavierFNN (layers_all=layers, mode=mode)

output = model(input_tensor)

</code></pre>
<h2 id="residual-neural-network">Residual neural network</h2>
<pre><code>CLASS: src.neural_network.ResNet(layers_all: List[int], blocks: List[int], res_block: nn.Module, activation_function_array: List[nn.Module])
</code></pre>
<p>Модель включает в себя классы ResNet и LightResidualBlock. В самой модели задается количество линейных блоков и нейронов для каждого блока соответственно, более того при задании класса требуется передать вид линейного блока (LightResidualBlock) и функции активации, которые будут соединять линейные слои в блоках. Во время обучения происходит передача данных обучения между нейронами, при котором пропускается часть слоев через блоки линейных слоев, что дает большой клад в обучения и устойчивость модели. 
<img alt="ResNet" src="https://github.com/liskiran/pinn_docs/blob/main/docs/resnet.jpg" />
<strong>Параметры</strong></p>
<ul>
<li><strong>layers_all</strong>(List) – список, содержащий количества нейроннов для каждого блока слоев Resnet.<blockquote>
<p><strong><em>Важно:</em></strong>  Первое и последнее значение массива нейронов должно соответствовать геометрии задачи и количеству выводов.</p>
</blockquote>
</li>
<li><strong>blocks</strong>(List) – список, содержащий количество блоков для каждого количества нейроннов<blockquote>
<p><strong><em>Важно:</em></strong>  При подаче None для каждого слоя будет использовать один блок.</p>
</blockquote>
</li>
<li><strong>res_block</strong>(nn.Module) - блок ResNet, реализованный на базе ResidualBlock.</li>
<li><strong>activation_function_array</strong>(List) – список, содержащий функции активации, которые используются при обучении.</li>
</ul>
<p><strong>Методы</strong></p>
<pre><code>forward(x: torch.Tensor)
</code></pre>
<p><strong>Параметр</strong></p>
<pre><code>x (torch.Tensor) - входной тензор данных для прямого прохода модели.
</code></pre>
<p>Выполняет прямой проход обучения модели. </p>
<pre><code>__make_layers(res_block: nn.Module,count_blocks: int,in_features: int,out_features: int,activation: nn.Module, is_not_last: bool):
</code></pre>
<p><strong>Параметры</strong>
   - res_block (nn.Module) - блок Residual neural network, реализованный на базе ResidualBlock.
   - count_blocks (int) - колличество блоков модели.
   - in_features (int) - колличество входных нейронов в слой блока.
   - out_features (int) - колличество выходных нейронов в слой блока.
   - activation (nn.Module) - функция активации, соеденяющаяя линейнные слои.
   - is_not_last (bool) - ограничение, показывающее, что следующего блока ResNet нет.</p>
<p>Конструирует блоки ResidualBlock одного размера и последующий линейнный слой новой размерности.</p>
<p><strong>Примеры использования:</strong></p>
<pre><code class="language-python">from src.neural_network import ResNet

# Определение входных и выходных нейронов 
input_size = 2

output_size = 1

# Определение слоев нейронов в модели
layers = [input_size, 5, 10, 15, 20, 25, output_size]

# Определение слоев нейронов в модели
blocks = [1, 6, 5, 6, 2]


# Определение модели
model = ResNet(layers_all=layers, blocks = blocks)

# Выполнение прямого прохода модели
output = model(input_tensor)

</code></pre>
<h2 id="residual-block">Residual block</h2>
<pre><code>  CLASS: src.neural_network. LightResidualBlock (activation: nn.Module, features: int)
</code></pre>
<p>Архитектура блока в модели Residual neural network. На вход блок сети принимает входные и выходные значения для линейных слоев и функцию активации для связи блоков.В блоке создается как минимум два одинаковых линейнных слоя, соеденные функцией активации.</p>
<p><strong>Параметры</strong></p>
<ul>
<li><strong>features</strong>(int) – Размерность входных данных.</li>
<li><strong>activation</strong>(nn.Module) – функция активации.</li>
</ul>
<p><strong>Метод</strong></p>
<pre><code>forward(x: torch.Tensor)
</code></pre>
<p><strong>Параметр</strong></p>
<pre><code>x (torch.Tensor) – входной тензор данных для прямого прохода модели.
</code></pre>
<p>Выполняет прямой проход обучения блока модели ResNet.</p>
<p><strong>Пример</strong></p>
<p>layer = LightResidualBlock(nn.GeLU(), 64)</p>
<p><strong>Примеры использования:</strong></p>
<pre><code class="language-python">from src.neural_network import LightResidualBlock
from src.neural_network.activation_function import GeLU

input_neuron = 64

# Определение функции активации и блока модели 
gelu = GeLU()

layer = LightResidualBlock(features = input_neuron, activation = gelu)

</code></pre>
<h2 id="densely-connected-linear-networks">Densely connected linear networks</h2>
<pre><code>CLASS: src.neural_network.DenseNet(layers_all: List[int], blocks: List[int])
</code></pre>
<p>Архитектура модели включает в себя классы DenseNet и DenseBlock. В архитектуре задается количество линейных блоков и нейронов для каждого блока соответственно. Во время обучения происходит передача данных с каждого слоя на каждый, благодаря чему нейронная сеть получает больше информации о задаче.</p>
<p><strong>Параметры</strong></p>
<ul>
<li><strong>layers_all</strong> (List) - список нейронов по слоям для обучения.<blockquote>
<p><strong><em>Важно:</em></strong>  Первое и последнее значение массива нейронов должно соответствовать геометрии задачи и количеству выводов.</p>
</blockquote>
</li>
<li><strong>blocks</strong>(List) – список, содержащий количество блоков (DenseBlock) для каждого количества нейроннов.</li>
</ul>
<p><strong>Метод</strong></p>
<pre><code>forward(x: torch.Tensor)
</code></pre>
<p><strong>Параметр</strong></p>
<pre><code>x (torch.Tensor) - входной тензор данных для прямого прохода модели.
</code></pre>
<p>Выполняет прямой проход обучения блока модели DenseNet.</p>
<h2 id="densely-block">Densely block</h2>
<pre><code>CLASS: src.neural_network.DenseBlock(activation: nn.Module , dimension_layer: int, features: int)
</code></pre>
<p>Архитектура блока в модели Densely connected linear networks, благодаря которому происходит передача данных между слоями. На вход блок сети принимает входные и выходные значения для линейных слоев и функцию активации для связи блоков.</p>
<p><strong>Параметры</strong></p>
<ul>
<li><strong>activation</strong> (nn.Module) - функция активации.</li>
<li><strong>dimension_layer</strong>(int) – количество блоков (Densely block).</li>
<li><strong>features</strong>(int) - размерность входных и выходных данных данных.</li>
</ul>
<p><strong>Метод</strong></p>
<pre><code>forward(self, x: torch.Tensor)
</code></pre>
<p><strong>Параметр</strong>
    x (torch.Tensor) - входной тензор данных для прямого прохода модели.</p>
<h2 id="gelu">GELU</h2>
<pre><code>CLASS: src.neural_network.activation_function.GELU(nn.Module)
</code></pre>
<p>Функция активации GeLU с ускорением расчетов в процессе обучения.</p>
<p><strong>Метод</strong></p>
<pre><code>forward(input: torch.Tensor)
</code></pre>
<p><strong>Параметр</strong></p>
<pre><code>input (torch.Tensor) - входной тензор данных для прямого прохода функции.
</code></pre>
<p>Выполняет прямой проход функции активации во время обучения модели с оптимизацией torch.jit.script.</p>
<p><strong>Пример использования:</strong></p>
<pre><code class="language-python">from src.neural_network.activation_function import GeLU

# Определение функции активации
gelu = GeLU()

output = gelu(input_tensor)

</code></pre>
<h2 id="sine">Sine</h2>
<pre><code>CLASS: src.neural_network.activation_function.Sine(nn.Module)
</code></pre>
<p>Адаптиваня функция активации Siren с ускорением расчетов в процессе обучения.</p>
<p><strong>Метод</strong></p>
<pre><code>forward(input: torch.Tensor)
</code></pre>
<p><strong>Параметр</strong></p>
<pre><code>input (torch.Tensor) - входной тензор данных для прямого прохода функции.
</code></pre>
<p>Выполняет прямой проход адаптивной функции синуса во время обучения модели с оптимизацией torch.jit.script.</p>
<p><strong>Пример использования:</strong></p>
<pre><code class="language-python">from src.neural_network.activation_function import Sine

# Определение функции активации
sine = Sine()

output = sine(input_tensor)

</code></pre>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.aecac24b.min.js"></script>
      
    
  </body>
</html>